\section{Problema 4}

Sea $Y$ una variable aleatoria que representa el número de éxitos en $\mathrm{n}$ intentos independientes con probabilidad p de éxito en cada intento. Además,
$$
Y=\sum_{i=1}^{n} Y_{i}
$$
donde
$$
Y_{i}=\begin{cases}
	1  , & \text { si el i-ésimo intento resulta en éxito } \\
	0  , & \text { en el otro caso }
\end{cases}
$$
para $\mathrm{i}=1, \ldots, \mathrm{n}$
\begin{enumerate}
	\item a) Demuestre que $\widehat{p_{n}}=\frac{Y}{n}$ es un estimador insesgado de $p$.
	\begin{solution} Tenemos las siguientes denificiones:: 
		\begin{tcolorbox}[colback=gray!15,colframe=black!1!black,title=Definición 8.2 - Sesgo ]
			Let $\hat{\theta}$ be a point estimator for a parameter $\theta$. Then $\hat{\theta}$  is an unbiased estimator if $E(\hat{\theta})=\theta$. If$E(\hat{\theta})\neq \theta$, $\theta$ is said to be biased.
			\end{tcolorbox}
		
		\begin{tcolorbox}[colback=gray!15,colframe=black!1!black,title=Definición 8.3 - Sesgo ]
			The bias of a point estimator $\hat{\theta}$ is given by $B(\hat{\theta}) = E(\hat{\theta}) - \theta $.
		\end{tcolorbox}
	A probar: $E(\hat{p}_n)=p$.  Entonces:

	$$E(\hat{p}_n)=E\left(\frac{Y}{n}\right)=\underbrace{\frac{1}{n}E(Y)}_{\text{Teorema 5.7}}=\frac{1}{n}E\left(\sum_{i=1}^{n}Y_i\right)=\frac{1}{n}E\left(Y_1+Y_2+\cdots +Y_n\right)=$$
	$$=\frac{1}{n}\left[\underbrace{E(Y_1)+E(Y_2)+\cdots + E(Y_n)}_{E(Y_i)=p \text{, definición de valor esperado.}}\right]=\frac{1}{n}\left[p+p+\cdots+p\right]=\frac{1}{n}(np)=p$$
	
	\end{solution}
	\item b) Demuestre que $\widehat{p_{n}}$ es un estimador consistente de $p$.
	\begin{solution} 
		Procedemos a calcular la varianza del estimador, es decir: 
		$$VAR(\hat{p}_n)=\frac{pq}{n}. \quad \text{ (Deducción en el ejercicio 5.28).}$$
		$\implies$ Tomamos como referencia el teorema 9.1:
		\begin{tcolorbox}[colback=gray!15,colframe=black!1!black,title=Teorema 9.1]
			An unbiased estimator $\hat{\theta}_n$ for $\theta$ is a consistent estimator of $\theta$ if
			$$\lim_{n\to\infty}VAR(\hat{\theta}_n)=0.$$
		\end{tcolorbox}
	$$\implies \lim_{n\to\infty}VAR(\hat{p}_n)=\lim_{n\to\infty}VAR\left(\frac{pq}{n}\right)=VAR\left(\frac{pq}{0}\right)=0.$$
	\end{solution}
	\item c) Cuando $\mathrm{n}$ es grande, demuestre que la distribución de $\frac{\widehat{p_{n}}-p}{\sqrt{p(1-p) / n}}$ converge a una distribución normal estándar.
	\begin{solution}
		Considerando: \begin{tcolorbox}[colback=gray!15,colframe=black!1!black,title=Teorema 9.3]
			Suppose that $U_n$ has a distribution function that converges to a standard normal distribution function as $n \to \infty$. If $W_n$ converges in probability to 1, then the distribution function of $U_n / W_n $converges to a standard normal distribution function.
			\end{tcolorbox}
	\end{solution}
	\item d) Cuando $\mathrm{n}$ es grande, demuestre que la distribución de $\frac{\widehat{p_{n}}-p}{\sqrt{p_{n}\left(1-\widehat{p_{n}}\right) / n}}$ converge a una distribución normal estándar. 
	\begin{solution}
		Considerando: \begin{tcolorbox}[colback=gray!15,colframe=black!1!black,title=Teorema 9.3]
			Suppose that $U_n$ has a distribution function that converges to a standard normal distribution function as $n \to \infty$. If $W_n$ converges in probability to 1, then the distribution function of $U_n / W_n $converges to a standard normal distribution function.
		\end{tcolorbox}
	\end{solution}
\end{enumerate}
(Valor 25 puntos)
